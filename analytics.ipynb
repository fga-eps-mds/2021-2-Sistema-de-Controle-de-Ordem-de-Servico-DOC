{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytics - Product Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Date: 2022/02\n",
    "\n",
    "#### SUMMARY:\n",
    "\n",
    "- This notebook represents the project quality analysis of the date exposed right above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEAM:\n",
    "\n",
    "##### Semester: 2022/01\n",
    "##### Professor: Hilmer Neri\n",
    "\n",
    "##### Members:\n",
    "\n",
    "- Guilherme Leal\n",
    "- João Pedro Soares\n",
    "- Lucas Alexandre\n",
    "- Matheus Estanislau\n",
    "- Moacir Mascarenha\n",
    "- Igor Silva de Paiva\n",
    "- João Pedro Alves Machado\n",
    "- Mário Vinícius\n",
    "- Lucas Heler Lopes\n",
    "- Pedro Siqueira\n",
    "- Wildemberg Sales da Silva Junior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with data\n",
    "import pandas as pd\n",
    "import json\n",
    "from glob import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Deal with visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Deal with time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRAPH SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATAFRAME SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace your semester, project name, repository name, and the programming language extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "language = [['fga-eps-mds-2022-1-Alectrion-UserAPI', 'ts'],\n",
    "            ['fga-eps-mds-2022-1-Alectrion-FrontEnd', 'ts'],\n",
    "            ['fga-eps-mds-2022-1-Alectrion-EquipamentApi', 'ts']]\n",
    "\n",
    "repos_language = {}\n",
    "\n",
    "for item in language:\n",
    "    repos_language[f\"{item[0]}\"] = item[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SonarCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Path to the folder with all your jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsons = glob('analytics-raw-data/*.json') # add your path here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(json_path):\n",
    "    \n",
    "    with open(json_path) as json_file:\n",
    "        json_obj = json.load(json_file)\n",
    "        \n",
    "    return json_obj\n",
    "\n",
    "def create_base_component_df(json_list):\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for i in json_list:\n",
    "\n",
    "        base_component = read_json(i)\n",
    "\n",
    "        base_component_data = base_component['baseComponent']['measures']\n",
    "\n",
    "        base_component_df = pd.DataFrame(base_component_data)\n",
    "\n",
    "        base_component_df['filename'] = os.path.basename(i)\n",
    "\n",
    "        df = df.append(base_component_df, ignore_index=True)\n",
    "        \n",
    "    # Replace the UnB semester with yours.\n",
    "    aux_df = df['filename'].str.split(r\"fga-eps-mds-2022-1-(.*?)-(.*?)-(.*?)-(.*?)-v(.*?).json\", expand=True)\n",
    "    \n",
    "    df['repository'] = aux_df[2]\n",
    "    \n",
    "    df['version'] = aux_df[5]\n",
    "\n",
    "    df = df.sort_values(by=['repository', 'version'])\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create base component dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10461/108625875.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/108625875.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/108625875.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/108625875.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/108625875.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/108625875.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/108625875.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/108625875.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/108625875.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/108625875.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/108625875.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/108625875.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/108625875.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/108625875.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/108625875.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/108625875.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/108625875.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/108625875.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/108625875.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/108625875.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/108625875.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/108625875.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/108625875.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/108625875.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "base_component_df = create_base_component_df(jsons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "      <th>bestValue</th>\n",
       "      <th>filename</th>\n",
       "      <th>repository</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>duplicated_lines_density</td>\n",
       "      <td>1.9</td>\n",
       "      <td>False</td>\n",
       "      <td>fga-eps-mds-2022-1-Alectrion-EquipamentApi-09-...</td>\n",
       "      <td>EquipamentApi</td>\n",
       "      <td>0.11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>functions</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fga-eps-mds-2022-1-Alectrion-EquipamentApi-09-...</td>\n",
       "      <td>EquipamentApi</td>\n",
       "      <td>0.11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>test_execution_time</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fga-eps-mds-2022-1-Alectrion-EquipamentApi-09-...</td>\n",
       "      <td>EquipamentApi</td>\n",
       "      <td>0.11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>test_failures</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>fga-eps-mds-2022-1-Alectrion-EquipamentApi-09-...</td>\n",
       "      <td>EquipamentApi</td>\n",
       "      <td>0.11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>test_errors</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>fga-eps-mds-2022-1-Alectrion-EquipamentApi-09-...</td>\n",
       "      <td>EquipamentApi</td>\n",
       "      <td>0.11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>security_rating</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>fga-eps-mds-2022-1-Alectrion-EquipamentApi-09-...</td>\n",
       "      <td>EquipamentApi</td>\n",
       "      <td>0.11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>tests</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fga-eps-mds-2022-1-Alectrion-EquipamentApi-09-...</td>\n",
       "      <td>EquipamentApi</td>\n",
       "      <td>0.11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>files</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fga-eps-mds-2022-1-Alectrion-EquipamentApi-09-...</td>\n",
       "      <td>EquipamentApi</td>\n",
       "      <td>0.11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>complexity</td>\n",
       "      <td>121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fga-eps-mds-2022-1-Alectrion-EquipamentApi-09-...</td>\n",
       "      <td>EquipamentApi</td>\n",
       "      <td>0.11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>ncloc</td>\n",
       "      <td>870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fga-eps-mds-2022-1-Alectrion-EquipamentApi-09-...</td>\n",
       "      <td>EquipamentApi</td>\n",
       "      <td>0.11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      metric value bestValue  \\\n",
       "84  duplicated_lines_density   1.9     False   \n",
       "85                 functions    45       NaN   \n",
       "86       test_execution_time    63       NaN   \n",
       "87             test_failures     0      True   \n",
       "88               test_errors     0      True   \n",
       "89           security_rating   1.0      True   \n",
       "90                     tests    42       NaN   \n",
       "91                     files    19       NaN   \n",
       "92                complexity   121       NaN   \n",
       "93                     ncloc   870       NaN   \n",
       "\n",
       "                                             filename     repository version  \n",
       "84  fga-eps-mds-2022-1-Alectrion-EquipamentApi-09-...  EquipamentApi  0.11.0  \n",
       "85  fga-eps-mds-2022-1-Alectrion-EquipamentApi-09-...  EquipamentApi  0.11.0  \n",
       "86  fga-eps-mds-2022-1-Alectrion-EquipamentApi-09-...  EquipamentApi  0.11.0  \n",
       "87  fga-eps-mds-2022-1-Alectrion-EquipamentApi-09-...  EquipamentApi  0.11.0  \n",
       "88  fga-eps-mds-2022-1-Alectrion-EquipamentApi-09-...  EquipamentApi  0.11.0  \n",
       "89  fga-eps-mds-2022-1-Alectrion-EquipamentApi-09-...  EquipamentApi  0.11.0  \n",
       "90  fga-eps-mds-2022-1-Alectrion-EquipamentApi-09-...  EquipamentApi  0.11.0  \n",
       "91  fga-eps-mds-2022-1-Alectrion-EquipamentApi-09-...  EquipamentApi  0.11.0  \n",
       "92  fga-eps-mds-2022-1-Alectrion-EquipamentApi-09-...  EquipamentApi  0.11.0  \n",
       "93  fga-eps-mds-2022-1-Alectrion-EquipamentApi-09-...  EquipamentApi  0.11.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_component_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataframe per file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_list = ['files',\n",
    "               'functions',\n",
    "               'complexity',\n",
    "               'comment_lines_density',\n",
    "               'duplicated_lines_density',\n",
    "               'coverage',\n",
    "               'ncloc',\n",
    "               'tests',\n",
    "               'test_errors',\n",
    "               'test_failures',\n",
    "               'test_execution_time',\n",
    "               'security_rating']\n",
    "\n",
    "len(metric_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_files_df(df):\n",
    "    \n",
    "    files = df[df['qualifier'] == 'FIL'] \n",
    "    \n",
    "    files = files.dropna(subset=['functions', 'complexity','comment_lines_density', 'duplicated_lines_density', 'coverage' ])\n",
    "    \n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_dir_df(df):\n",
    "    dirs = df[df[\"qualifier\"] == \"DIR\"]     \n",
    "        \n",
    "    dirs = dirs.dropna(subset=['tests', 'test_errors','test_failures'])\n",
    "    \n",
    "    newdf = pd.to_numeric(dirs[\"tests\"])\n",
    "    \n",
    "    max_value_index = newdf.idxmax()            \n",
    "    \n",
    "    return dirs.loc[max_value_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uts_df(df):\n",
    "    dirs = df[df['qualifier'] == 'UTS']     \n",
    "\n",
    "    dirs = dirs.dropna(subset=['test_execution_time'])          \n",
    "    \n",
    "    return dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_per_file(json):\n",
    "    \n",
    "    file_json = []\n",
    "    \n",
    "    for component in json['components']:\n",
    "        \n",
    "        ncloc_value = 0;\n",
    "        \n",
    "        for valores in component['measures']:\n",
    "\n",
    "            if valores['metric'] == 'ncloc':\n",
    "                ncloc_value = float(valores['value'])\n",
    "                break\n",
    "    \n",
    "        if (component['qualifier'] == 'FIL') & (ncloc_value > 0) or (component['qualifier'] == 'DIR') or (component['qualifier'] == 'UTS'):                       \n",
    "            file_json.append(component)\n",
    "\n",
    "    return file_json\n",
    "\n",
    "def generate_file_dataframe_per_release(metric_list, json, language_extension):\n",
    "    \n",
    "    df_columns = metric_list\n",
    "    df = pd.DataFrame(columns = df_columns)\n",
    "    df2 = pd.DataFrame(columns = df_columns)\n",
    "    df3 = pd.DataFrame(columns = df_columns)\n",
    "    \n",
    "    \n",
    "    for file in json:\n",
    "        try:\n",
    "                if file['qualifier'] == 'FIL' and file['language'] == language_extension:\n",
    "                    for measure in file['measures']:\n",
    "                        df.at[file['path'], measure['metric']] = measure['value']\n",
    "\n",
    "                    df['qualifier'] = file['qualifier'] \n",
    "\n",
    "                elif file['qualifier'] == 'UTS':  \n",
    "                    for measure in file['measures']:\n",
    "                        df3.at[file['path'], measure['metric']] = measure['value']\n",
    "\n",
    "                    df3['qualifier'] = file['qualifier'] \n",
    "                elif file['qualifier'] == 'DIR':\n",
    "                    for measure in file['measures']:\n",
    "                        df2.at[file['path'], measure['metric']] = measure['value']\n",
    "                    df2['qualifier'] = file['qualifier'] \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    df.reset_index(inplace = True)\n",
    "    df2.reset_index(inplace = True)\n",
    "    df3.reset_index(inplace = True)\n",
    "    df = df.rename({'index': 'path'}, axis=1).drop(['files'], axis=1)\n",
    "    df2 = df2.rename({'index': 'path'}, axis=1).drop(['files'], axis=1)\n",
    "    df3 = df3.rename({'index': 'path'}, axis=1).drop(['files'], axis=1)\n",
    "\n",
    "    dfFinal = pd.concat([df,df2,df3], axis=0)\n",
    "\n",
    "    return dfFinal\n",
    "\n",
    "def create_file_df(json_list):\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    dfDir = pd.DataFrame()\n",
    "\n",
    "    for i in json_list:\n",
    "\n",
    "        file_component = read_json(i)\n",
    "        \n",
    "        file_component_data = metric_per_file(file_component)\n",
    "                        \n",
    "        file_name = os.path.basename(i)\n",
    "\n",
    "        file_repository = re.split(r'-(\\d+-\\d+-\\d+-\\d+-\\d+-\\d+)-v(.*?).json', file_name)[0]\n",
    "\n",
    "        file_language = repos_language[f\"{file_repository}\"]\n",
    "\n",
    "        file_component_df = generate_file_dataframe_per_release(metric_list, file_component_data, language_extension = file_language)\n",
    "        \n",
    "        file_component_df['filename'] = os.path.basename(i)\n",
    "\n",
    "        df = df.append(file_component_df, ignore_index=True)\n",
    "        \n",
    "    # Replace the UnB semester with yours.\n",
    "    \n",
    "    aux_df = df['filename'].str.split(r\"-(\\d+-\\d+-\\d+-\\d+-\\d+-\\d+)-v(.*?).json\", expand=True)\n",
    "\n",
    "    df['repository'] = aux_df[0]\n",
    "\n",
    "    df['version'] = aux_df[2]\n",
    "\n",
    "    df = df.sort_values(by=['version'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10461/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_10461/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['fga-eps-mds-2022-1-Alectrion-FrontEnd',\n",
       "       'fga-eps-mds-2022-1-Alectrion-UserAPI',\n",
       "       'fga-eps-mds-2022-1-Alectrion-EquipamentApi'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_component_df = create_file_df(jsons)\n",
    "file_component_df.repository.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#file_component_df = file_component_df.dropna(subset=['functions', 'complexity','comment_lines_density', 'duplicated_lines_density', 'coverage' ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        ### Create dataframe per repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example. You must replace repo1, repo1,..., for your repository's names\n",
    "\n",
    "repo1_df = file_component_df[file_component_df['repository'] == 'fga-eps-mds-2022-1-Alectrion-UserAPI']\n",
    "repo2_df = file_component_df[file_component_df['repository'] == 'fga-eps-mds-2022-1-Alectrion-FrontEnd']\n",
    "repo3_df = file_component_df[file_component_df['repository'] == 'fga-eps-mds-2022-1-Alectrion-EquipamentApi']\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def _ncloc(df):\n",
    "    ncloc = 0\n",
    "    for each in df['ncloc']:\n",
    "        n = 0\n",
    "        # try to cast the current ncloc value to int, if the value is NaN/Null, consider it as zero.\n",
    "        try:\n",
    "            n = int(each)\n",
    "        except ValueError:\n",
    "            n = 0\n",
    "        ncloc += n\n",
    "\n",
    "    return ncloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure calculations according Q-Rapids quality model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality Aspect - Maintainability\n",
    "## Factor - Code Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### COMPLEXITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m1(df):\n",
    "\n",
    "    files_df = get_files_df(df)\n",
    "    density_non_complex_files = 0\n",
    "    try:\n",
    "        density_non_complex_files = len(files_df[(files_df['complexity'].astype(float) /\n",
    "                                              files_df['functions'].astype(float)) < 10]) / len(files_df)\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    \n",
    "    return density_non_complex_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### COMMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m2(df):\n",
    "\n",
    "    files_df = get_files_df(df)\n",
    "    density_comment_files = 0\n",
    "    try:\n",
    "        density_comment_files = len(files_df[(files_df['comment_lines_density'].astype(float) > 10) &\n",
    "                                         (files_df['comment_lines_density'].astype(float) < 30)]) / len(files_df)\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    \n",
    "    return density_comment_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DUPLICATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m3(df):\n",
    "    \n",
    "    files_df = get_files_df(df)\n",
    "    duplication = 0\n",
    "    \n",
    "    try:\n",
    "        duplication = len(files_df[(files_df['duplicated_lines_density'].astype(float) < 5)])/len(files_df)\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "        \n",
    "    return duplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality Aspect - Reliability\n",
    "## Factor - Testing Status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Passed tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def m4(df):\n",
    "    \n",
    "    cont = 0\n",
    "    dir_df = get_dir_df(df)\n",
    "    passed_tests = 0\n",
    "    \n",
    "    try:\n",
    "        passed_tests = (float(dir_df['tests']) - (float(dir_df['test_errors']) + float(dir_df['test_failures']))) /\\\n",
    "                   float(dir_df['tests'])\n",
    "    except ValueError:\n",
    "        cont+=1\n",
    "        \n",
    "    return passed_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fast test builds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def m5(df):\n",
    "\n",
    "    dir_df = get_uts_df(df)\n",
    "    density_fast_test_builds = 0\n",
    "    \n",
    "    try:\n",
    "        density_fast_test_builds = len(dir_df[(dir_df['test_execution_time'].astype(float)) < 300000]) /\\\n",
    "                               len(dir_df['test_execution_time'].astype(float))\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    \n",
    "    return density_fast_test_builds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def m6(df):\n",
    "\n",
    "    files_df = get_files_df(df)\n",
    "    density_test_coverage = 0\n",
    "    try:\n",
    "        density_test_coverage = len(files_df[(files_df['coverage'].astype(float) > 60)]) / len(files_df)\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    \n",
    "    return density_test_coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate m1, m2, m3, m4, m5 and m6 for each repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metrics_df(df):\n",
    "    \n",
    "    version_vec = df['version'].unique()\n",
    "    \n",
    "    m1_list = []\n",
    "    m2_list = []\n",
    "    m3_list = []\n",
    "    m4_list = []\n",
    "    m5_list = []\n",
    "    m6_list = []\n",
    "\n",
    "    ncloc_list = []\n",
    "    repository_list = []\n",
    "    version_list = []\n",
    "    \n",
    "    for version in version_vec:\n",
    "\n",
    "        version_df = df[df['version'] == version]\n",
    "        \n",
    "        m1_list.append(m1(version_df))\n",
    "        m2_list.append(m2(version_df))\n",
    "        m3_list.append(m3(version_df))\n",
    "        m4_list.append(m4(version_df))\n",
    "        m5_list.append(m5(version_df))\n",
    "        m6_list.append(m6(version_df))\n",
    "\n",
    "        ncloc_list.append(_ncloc(version_df))\n",
    "        repository_list.append(version_df['repository'].iloc[0])\n",
    "        version_list.append(version)\n",
    "        \n",
    "    metrics_df = pd.DataFrame({'m1': m1_list,\n",
    "                               'm2': m2_list,\n",
    "                               'm3': m3_list,\n",
    "                               'm4': m4_list,\n",
    "                               'm5': m5_list,\n",
    "                               'm6': m6_list,\n",
    "                               'repository': repository_list, \n",
    "                               'version': version_list,\n",
    "                               'ncloc': ncloc_list})\n",
    "      \n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmax of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m repo1 \u001b[38;5;241m=\u001b[39m create_metrics_df(repo1_df)\n\u001b[1;32m      2\u001b[0m repo2 \u001b[38;5;241m=\u001b[39m create_metrics_df(repo2_df)\n\u001b[0;32m----> 3\u001b[0m repo3 \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_metrics_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo3_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36mcreate_metrics_df\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     21\u001b[0m m2_list\u001b[38;5;241m.\u001b[39mappend(m2(version_df))\n\u001b[1;32m     22\u001b[0m m3_list\u001b[38;5;241m.\u001b[39mappend(m3(version_df))\n\u001b[0;32m---> 23\u001b[0m m4_list\u001b[38;5;241m.\u001b[39mappend(\u001b[43mm4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mversion_df\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     24\u001b[0m m5_list\u001b[38;5;241m.\u001b[39mappend(m5(version_df))\n\u001b[1;32m     25\u001b[0m m6_list\u001b[38;5;241m.\u001b[39mappend(m6(version_df))\n",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36mm4\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mm4\u001b[39m(df):\n\u001b[1;32m      3\u001b[0m     cont \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 4\u001b[0m     dir_df \u001b[38;5;241m=\u001b[39m \u001b[43mget_dir_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     passed_tests \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36mget_dir_df\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      4\u001b[0m dirs \u001b[38;5;241m=\u001b[39m dirs\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtests\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_errors\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_failures\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      6\u001b[0m newdf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(dirs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtests\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 8\u001b[0m max_value_index \u001b[38;5;241m=\u001b[39m \u001b[43mnewdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43midxmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m            \n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dirs\u001b[38;5;241m.\u001b[39mloc[max_value_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/series.py:2404\u001b[0m, in \u001b[0;36mSeries.idxmax\u001b[0;34m(self, axis, skipna, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21midxmax\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   2340\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2341\u001b[0m \u001b[38;5;124;03m    Return the row label of the maximum value.\u001b[39;00m\n\u001b[1;32m   2342\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2402\u001b[0m \u001b[38;5;124;03m    nan\u001b[39;00m\n\u001b[1;32m   2403\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2404\u001b[0m     i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2405\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2406\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/base.py:657\u001b[0m, in \u001b[0;36mIndexOpsMixin.argmax\u001b[0;34m(self, axis, skipna, *args, **kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m delegate\u001b[38;5;241m.\u001b[39margmax()\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;66;03m# error: Incompatible return value type (got \"Union[int, ndarray]\", expected\u001b[39;00m\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;66;03m# \"int\")\u001b[39;00m\n\u001b[0;32m--> 657\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanargmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[1;32m    658\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/nanops.py:93\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 93\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(args[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/nanops.py:1096\u001b[0m, in \u001b[0;36mnanargmax\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m   1094\u001b[0m values, mask, _, _, _ \u001b[38;5;241m=\u001b[39m _get_values(values, \u001b[38;5;28;01mTrue\u001b[39;00m, fill_value_typ\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, mask\u001b[38;5;241m=\u001b[39mmask)\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;66;03m# error: Need type annotation for 'result'\u001b[39;00m\n\u001b[0;32m-> 1096\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[var-annotated]\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m result \u001b[38;5;241m=\u001b[39m _maybe_arg_null_out(result, axis, mask, skipna)\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
     ]
    }
   ],
   "source": [
    "repo1 = create_metrics_df(repo1_df)\n",
    "repo2 = create_metrics_df(repo2_df)\n",
    "repo3 = create_metrics_df(repo3_df)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visualization\n",
    "\n",
    "- You must do this for each of your repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alectrion UserAPI\n",
    "repo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Alectrion-UserApi')\n",
    "plt.plot(repo1['m1'], linewidth=3, marker='o', markersize=10, color=\"magenta\", label=\"Density non complex files\")\n",
    "plt.plot(repo1['m2'], linewidth=3, marker='o', markersize=10, color=\"blue\", label=\"Density comment files\")\n",
    "plt.plot(repo1['m3'], linewidth=3, marker='o', markersize=10, color=\"green\", label=\"Duplication\")\n",
    "plt.plot(repo1['m4'], linewidth=3, marker='o', markersize=10, color=\"yellow\", label=\"Passed tests\")\n",
    "plt.plot(repo1['m5'], linewidth=3, marker='o', markersize=10, color=\"black\", label=\"Density fast test builds\")\n",
    "plt.plot(repo1['m6'], linewidth=3, marker='o', markersize=10, color=\"red\", label=\"Density test coverage\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Alectrion-UserApi Manutenabilidade')\n",
    "plt.plot(repo1['m1'], linewidth=3, marker='o', markersize=10, color=\"magenta\", label=\"Density non complex files\")\n",
    "plt.plot(repo1['m2'], linewidth=3, marker='o', markersize=10, color=\"blue\", label=\"Density comment files\")\n",
    "plt.plot(repo1['m3'], linewidth=3, marker='o', markersize=10, color=\"green\", label=\"Duplication\")\n",
    "plt.legend()\n",
    "pfname=\"data/manutenabilidade\"\n",
    "plt.savefig(pfname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Alectrion-UserApi Confiabilidade')\n",
    "plt.plot(repo1['m4'], linewidth=3, marker='o', markersize=10, color=\"yellow\", label=\"Passed tests\")\n",
    "plt.plot(repo1['m5'], linewidth=3, marker='o', markersize=10, color=\"black\", label=\"Density fast test builds\")\n",
    "plt.plot(repo1['m6'], linewidth=3, marker='o', markersize=10, color=\"red\", label=\"Density test coverage\")\n",
    "plt.legend()\n",
    "pfname=\"data/confiabilidade\"\n",
    "plt.savefig(pfname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alectrion FrontEnd\n",
    "repo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.title('Alectrion-FrontEnd')\n",
    "plt.plot(repo2['m1'], linewidth=3, marker='o', markersize=10, color=\"magenta\", label=\"Density non complex files\")\n",
    "plt.plot(repo2['m2'], linewidth=3, marker='o', markersize=10, color=\"blue\", label=\"Density comment files\")\n",
    "plt.plot(repo2['m3'], linewidth=3, marker='o', markersize=10, color=\"green\", label=\"Duplication\")\n",
    "plt.plot(repo2['m4'], linewidth=3, marker='o', markersize=10, color=\"yellow\", label=\"Passed tests\")\n",
    "plt.plot(repo2['m5'], linewidth=3, marker='o', markersize=10, color=\"black\", label=\"Density fast test builds\")\n",
    "plt.plot(repo2['m6'], linewidth=3, marker='o', markersize=10, color=\"red\", label=\"Density test coverage\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Alectrion-FrontEnd Manutenabilidade')\n",
    "plt.plot(repo2['m1'], linewidth=3, marker='o', markersize=10, color=\"magenta\", label=\"Density non complex files\")\n",
    "plt.plot(repo2['m2'], linewidth=3, marker='o', markersize=10, color=\"blue\", label=\"Density comment files\")\n",
    "plt.plot(repo2['m3'], linewidth=3, marker='o', markersize=10, color=\"green\", label=\"Duplication\")\n",
    "plt.legend()\n",
    "pfname=\"data/manutenabilidade-front\"\n",
    "plt.savefig(pfname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Alectrion-FrontEnd Confiabilidade')\n",
    "plt.plot(repo2['m4'], linewidth=3, marker='o', markersize=10, color=\"yellow\", label=\"Passed tests\")\n",
    "plt.plot(repo2['m5'], linewidth=3, marker='o', markersize=10, color=\"black\", label=\"Density fast test builds\")\n",
    "plt.plot(repo2['m6'], linewidth=3, marker='o', markersize=10, color=\"red\", label=\"Density test coverage\")\n",
    "plt.legend()\n",
    "pfname=\"data/confiabilidade-front\"\n",
    "plt.savefig(pfname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alectrion EquipamentAPI\n",
    "repo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Alectrion-EquipamentApi')\n",
    "plt.plot(repo3['m1'], linewidth=3, marker='o', markersize=10, color=\"magenta\", label=\"Density non complex files\")\n",
    "plt.plot(repo3['m2'], linewidth=3, marker='o', markersize=10, color=\"blue\", label=\"Density comment files\")\n",
    "plt.plot(repo3['m3'], linewidth=3, marker='o', markersize=10, color=\"green\", label=\"Duplication\")\n",
    "plt.plot(repo3['m4'], linewidth=3, marker='o', markersize=10, color=\"yellow\", label=\"Passed tests\")\n",
    "plt.plot(repo3['m5'], linewidth=3, marker='o', markersize=10, color=\"black\", label=\"Density fast test builds\")\n",
    "plt.plot(repo3['m6'], linewidth=3, marker='o', markersize=10, color=\"red\", label=\"Density test coverage\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality factor and aspect aggregation\n",
    "\n",
    "- You must do this for each of your repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psc1 = 1\n",
    "psc2 = 1\n",
    "pc1 = 0.5\n",
    "pc2 = 0.5\n",
    "pm1 = 0.33\n",
    "pm2 = 0.33\n",
    "pm3 = 0.33\n",
    "pm4 = 0.25\n",
    "pm5 = 0.25\n",
    "pm6 = 0.5\n",
    "\n",
    "repo1['code_quality'] = ((repo1['m1']*pm1) + (repo1['m2']*pm2) + (repo1['m3']*pm3)) * psc1\n",
    "repo2['code_quality'] = ((repo2['m1']*pm1) + (repo2['m2']*pm2) + (repo2['m3']*pm3)) * psc1\n",
    "repo3['code_quality'] = ((repo3['m1']*pm1) + (repo3['m2']*pm2) + (repo3['m3']*pm3)) * psc1\n",
    "...\n",
    "\n",
    "repo1['testing_status'] = ((repo1['m4']*pm4) + (repo1['m5']*pm5) + (repo1['m6']*pm6)) * psc2\n",
    "repo2['testing_status'] = ((repo2['m4']*pm4) + (repo2['m5']*pm5) + (repo2['m6']*pm6)) * psc2\n",
    "repo3['testing_status'] = ((repo3['m4']*pm4) + (repo3['m5']*pm5) + (repo3['m6']*pm6)) * psc2\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Qualidade Alectrion')\n",
    "plt.plot(repo1['code_quality'], linewidth=3, marker='o', markersize=5, label=\"UserAPI\")\n",
    "plt.plot(repo2['code_quality'], linewidth=3, marker='o', markersize=5, label=\"FrontEnd\")\n",
    "plt.plot(repo3['code_quality'], linewidth=3, marker='o', markersize=5, label=\"EquipamentAPI\")\n",
    "plt.legend()\n",
    "plt.ylim([0.6,0.7])\n",
    "pfname=\"data/qualidade\"\n",
    "plt.savefig(pfname)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(repo1['testing_status'], linewidth=3, marker='o', markersize=5, label=\"UserAPI\")\n",
    "plt.plot(repo2['testing_status'], linewidth=3, marker='o', markersize=5, label=\"FrontEnd\")\n",
    "plt.plot(repo3['testing_status'], linewidth=3, marker='o', markersize=5, label=\"EquipamentAPI\")\n",
    "plt.legend()\n",
    "...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo1['Maintainability'] = repo1['code_quality'] * pc1\n",
    "repo1['Reliability'] = repo1['testing_status'] * pc2\n",
    "repo1['total'] = repo1['Maintainability'] + repo1['Reliability']\n",
    "\n",
    "repo2['Maintainability'] = repo2['code_quality'] * pc1\n",
    "repo2['Reliability'] = repo2['testing_status'] * pc2\n",
    "repo2['total'] = repo2['Maintainability'] + repo2['Reliability']\n",
    "\n",
    "repo3['Maintainability'] = repo3['code_quality'] * pc1\n",
    "repo3['Reliability'] = repo3['testing_status'] * pc2\n",
    "repo3['total'] = repo3['Maintainability'] + repo3['Reliability']\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alectrion USERAPI\n",
    "repo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(repo1['Maintainability'], linewidth=3, marker='o', markersize=5, label=\"Maintainability\")\n",
    "plt.plot(repo1['Reliability'], linewidth=3, marker='*', markersize=5, label=\"Reliability\")\n",
    "plt.plot(repo1['total'], linewidth=3, marker='X', markersize=5, label=\"total\")\n",
    "plt.legend()\n",
    "plt.ylim(0.1,1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Alectrion FrontEnd\n",
    "repo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(repo2['Maintainability'], linewidth=3, marker='o', markersize=5, label=\"Maintainability\")\n",
    "plt.plot(repo2['Reliability'], linewidth=3, marker='*', markersize=5, label=\"Reliability\")\n",
    "plt.plot(repo2['total'], linewidth=3, marker='X', markersize=5, label=\"total\")\n",
    "plt.legend()\n",
    "plt.ylim(0.1,1.1)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alectrion EquipamentAPI\n",
    "repo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(repo3['Maintainability'], linewidth=3, marker='o', markersize=5, label=\"Maintainability\")\n",
    "plt.plot(repo3['Reliability'], linewidth=3, marker='*', markersize=5, label=\"Reliability\")\n",
    "plt.plot(repo3['total'], linewidth=3, marker='X', markersize=5, label=\"total\")\n",
    "plt.legend()\n",
    "plt.ylim(0.1,1.1)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You must do the total plot and the statics analysis for the repository with more versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Building descriptive statistics dataframe. You must replace YourRepoName for your repository name with more product versions.\n",
    "\n",
    "metrics_df = pd.concat([repo1, repo2], ignore_index=True)\n",
    "\n",
    "more_versions_repo = metrics_df[metrics_df['repository'] == 'fga-eps-mds-2022-1-Alectrion-UserAPI']\n",
    "\n",
    "def get_characteristc_stats(repo_series):\n",
    "    return {\n",
    "        'mean': repo_series.mean(),\n",
    "        'mode': repo_series.mode(),\n",
    "        'median': repo_series.median(),\n",
    "        'std': repo_series.std(),\n",
    "        'var': repo_series.var(),\n",
    "        'min': repo_series.min(),\n",
    "        'max': repo_series.max()\n",
    "    }\n",
    "\n",
    "maintainability_stats = pd.DataFrame(get_characteristc_stats(more_versions_repo[\"Maintainability\"]),\n",
    "                                     columns=['mean', 'mode', 'median', 'std', 'var', 'min', 'max'])\n",
    "\n",
    "reliability_stats = pd.DataFrame(get_characteristc_stats(more_versions_repo[\"Reliability\"]),\n",
    "                                 columns=['mean', 'mode', 'median', 'std', 'var', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(maintainability_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(reliability_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the aggregated quality characteristic indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# boxplot\n",
    "plt.boxplot([more_versions_repo['Maintainability'], more_versions_repo['Reliability']],\n",
    "labels=['Maintainability', 'Reliability'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the aggregated repository quality indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(more_versions_repo['total'], linewidth=3, marker='o', markersize=5)\n",
    "\n",
    "plt.ylim(.1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATE FORMAT: MM-DD-YYYY-HH:MM:SS\n",
    "#currentDateTime = datetime.datetime.now().strftime(\"%m-%d-%Y-%H:%M:%S\")\n",
    "\n",
    "#metrics_df.to_excel('data/fga-eps-mds-2022-1-AlectrionFrontEnd-{}.xlsx'.format(currentDateTime), index = False)\n",
    "#metrics_df.to_csv('data/fga-eps-mds-2022-1-AlectrionFrontEnd-{}.csv'.format(currentDateTime), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Perguntas\n",
    "\n",
    "#### 1) Qual é o microsserviço de backend que apresenta o pior indicador de manutenibilidade e o que foi feito por seu time para melhorá-lo? \n",
    "\n",
    "    O Alectrion-UserApi apresenta o pior indicador de manutenibilidade, segundo a análise do notebook, mesmo apresentando bons indicativos de manutenibilidade, a pior indicada é a complexidade ciclomática.  \n",
    "\n",
    "    As métricas de densidade de comentários e duplicações apresentam os valores ideais para essas métricas. A complexidade de arquivos não complexos apresentam indicativos bons, porém é o único ponto a ser melhorado no serviço de userApi. Aplicamos alguns princípios do SOLID que visam facilitar o entendimento do código, principalmente o Princípio da responsabilidade única (Single Responsability Principle) que visa reduzir as responsabilidades das classes apenas para o domínio de sua operação e o Princípio da segregação de interfaces (Interface Segregation Principle) que visa que uma classe não deve ser obrigada a implementar métodos que ela não irá utilizar e também focamos na reutilização de código.\n",
    "\n",
    "\n",
    "#### 2) No microsserviço que apresenta o pior indicador de confiabilidade, mostre qual(is) o(s) módulos/arquivos mais críticos e explique como seu time tratou esse problema. \n",
    "\n",
    "\n",
    "Segundo os gráficos de confiabilidade apresentados nos microsserviços, o UserApi é o microsserviço com menor confiabilidade, pois a cobertura de teste no projeto ficou abaixo de 60%.\n",
    "A cobertura de teste em vários momentos do projeto ficou abaixo de 60% por conta de uma falha na configuração da coleta de cobertura, pois arquivos que não eram necessários foram testados (repository, entity, etc).\n",
    "Na análise nenhum teste apresentou falha, pois ao acontecer uma falha no CI não será enviado a análise para o sonar.\n",
    "Para aumentar a confiabilidade fizemos testes para arquivos com menor cobertura de testes\n",
    "\n",
    "\n",
    "#### 3) Explique o comportamento da qualidade do produto, observada durante o desenvolvimento do projeto relacionado ao seu time.\n",
    "\n",
    "\n",
    "Através das métricas colhidas foi possível observar que a qualidade do produto apresentou pouca variação durante o desenvolvimento. A maior variação encontrada aconteceu por conta da equipe no final da disciplina priorizar as funcionalidades para entrega do MVP, flexibilizando a cobertura de testes visando disponibilizar a funcionalidade para o cliente.\n",
    "\n",
    "Observações: \n",
    "O microsserviço api-gateway não foi incluído nas métricas visto que sua funcionalidade principal é o redirecionamento dos fluxos de requisições para os demais microsserviços e ao longo do semestre foram feitas apenas correções no código fonte.\n",
    "\n",
    "O microsserviço Alectrion-EquipamentApi não foi utilizado na análise do notebook, pois as métricas colhidas acarretam erros no processamento no analytics. Inviabilizando a comparação dos resultados com os outros microsserviços.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
